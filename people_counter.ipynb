{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import cvzone\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 317.2ms\n",
      "Speed: 15.5ms preprocess, 317.2ms inference, 128.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 76.7ms\n",
      "Speed: 3.0ms preprocess, 76.7ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 62.0ms\n",
      "Speed: 1.9ms preprocess, 62.0ms inference, 23.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.2ms\n",
      "Speed: 2.8ms preprocess, 58.2ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.3ms\n",
      "Speed: 2.4ms preprocess, 59.3ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 71.6ms\n",
      "Speed: 1.9ms preprocess, 71.6ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 61.8ms\n",
      "Speed: 2.4ms preprocess, 61.8ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.4ms\n",
      "Speed: 1.9ms preprocess, 54.4ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 54.5ms\n",
      "Speed: 2.0ms preprocess, 54.5ms inference, 67.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 55.2ms\n",
      "Speed: 1.7ms preprocess, 55.2ms inference, 22.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.3ms\n",
      "Speed: 3.0ms preprocess, 53.3ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 56.0ms\n",
      "Speed: 2.1ms preprocess, 56.0ms inference, 55.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.6ms\n",
      "Speed: 4.8ms preprocess, 53.6ms inference, 55.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 23.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.6ms\n",
      "Speed: 1.8ms preprocess, 52.6ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.1ms\n",
      "Speed: 1.7ms preprocess, 53.1ms inference, 62.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 55.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.2ms\n",
      "Speed: 1.7ms preprocess, 52.2ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.3ms\n",
      "Speed: 1.9ms preprocess, 53.3ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.6ms\n",
      "Speed: 1.7ms preprocess, 52.6ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 55.9ms\n",
      "Speed: 2.6ms preprocess, 55.9ms inference, 21.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.8ms\n",
      "Speed: 1.8ms preprocess, 52.8ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.2ms\n",
      "Speed: 1.7ms preprocess, 52.2ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.5ms\n",
      "Speed: 1.7ms preprocess, 52.5ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.2ms\n",
      "Speed: 2.0ms preprocess, 52.2ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 55.6ms\n",
      "Speed: 1.7ms preprocess, 55.6ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.7ms\n",
      "Speed: 1.7ms preprocess, 52.7ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 54.1ms\n",
      "Speed: 1.9ms preprocess, 54.1ms inference, 22.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.9ms\n",
      "Speed: 1.8ms preprocess, 52.9ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.6ms\n",
      "Speed: 1.6ms preprocess, 52.6ms inference, 55.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.4ms\n",
      "Speed: 1.8ms preprocess, 53.4ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.6ms\n",
      "Speed: 1.8ms preprocess, 52.6ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 51.9ms\n",
      "Speed: 1.9ms preprocess, 51.9ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 54.5ms\n",
      "Speed: 1.7ms preprocess, 54.5ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 51.8ms\n",
      "Speed: 1.7ms preprocess, 51.8ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.4ms\n",
      "Speed: 2.0ms preprocess, 53.4ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.2ms\n",
      "Speed: 3.3ms preprocess, 52.2ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.9ms\n",
      "Speed: 1.8ms preprocess, 52.9ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.9ms\n",
      "Speed: 1.7ms preprocess, 52.9ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.3ms\n",
      "Speed: 1.6ms preprocess, 53.3ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 53.7ms\n",
      "Speed: 1.9ms preprocess, 53.7ms inference, 72.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 53.9ms\n",
      "Speed: 1.7ms preprocess, 53.9ms inference, 56.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.4ms\n",
      "Speed: 5.0ms preprocess, 54.4ms inference, 82.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 56.0ms\n",
      "Speed: 4.2ms preprocess, 56.0ms inference, 58.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.1ms\n",
      "Speed: 1.8ms preprocess, 54.1ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.0ms\n",
      "Speed: 3.4ms preprocess, 53.0ms inference, 55.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.3ms\n",
      "Speed: 1.8ms preprocess, 53.3ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.3ms\n",
      "Speed: 1.8ms preprocess, 54.3ms inference, 20.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.0ms\n",
      "Speed: 1.9ms preprocess, 53.0ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.3ms\n",
      "Speed: 2.0ms preprocess, 53.3ms inference, 60.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 56.4ms\n",
      "Speed: 2.0ms preprocess, 56.4ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.1ms\n",
      "Speed: 1.9ms preprocess, 54.1ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.7ms\n",
      "Speed: 2.0ms preprocess, 54.7ms inference, 27.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 60.6ms\n",
      "Speed: 2.4ms preprocess, 60.6ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 56.4ms\n",
      "Speed: 3.8ms preprocess, 56.4ms inference, 22.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 55.8ms\n",
      "Speed: 1.8ms preprocess, 55.8ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 52.4ms\n",
      "Speed: 1.9ms preprocess, 52.4ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.4ms\n",
      "Speed: 1.7ms preprocess, 53.4ms inference, 58.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.6ms\n",
      "Speed: 1.7ms preprocess, 53.6ms inference, 21.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 54.0ms\n",
      "Speed: 1.9ms preprocess, 54.0ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 52.4ms\n",
      "Speed: 1.8ms preprocess, 52.4ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 57.3ms\n",
      "Speed: 2.2ms preprocess, 57.3ms inference, 43.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 56.9ms\n",
      "Speed: 2.0ms preprocess, 56.9ms inference, 25.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 57.6ms\n",
      "Speed: 2.0ms preprocess, 57.6ms inference, 67.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.1ms\n",
      "Speed: 1.8ms preprocess, 53.1ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 52.1ms\n",
      "Speed: 1.8ms preprocess, 52.1ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 52.8ms\n",
      "Speed: 2.9ms preprocess, 52.8ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 53.5ms\n",
      "Speed: 1.8ms preprocess, 53.5ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 52.3ms\n",
      "Speed: 1.7ms preprocess, 52.3ms inference, 22.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 train, 52.3ms\n",
      "Speed: 1.9ms preprocess, 52.3ms inference, 70.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 train, 53.3ms\n",
      "Speed: 1.7ms preprocess, 53.3ms inference, 57.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 train, 54.7ms\n",
      "Speed: 2.2ms preprocess, 54.7ms inference, 56.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 train, 53.4ms\n",
      "Speed: 1.9ms preprocess, 53.4ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 train, 52.4ms\n",
      "Speed: 1.6ms preprocess, 52.4ms inference, 56.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 train, 52.4ms\n",
      "Speed: 1.6ms preprocess, 52.4ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 54.0ms\n",
      "Speed: 1.9ms preprocess, 54.0ms inference, 55.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.6ms\n",
      "Speed: 1.7ms preprocess, 52.6ms inference, 55.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.1ms\n",
      "Speed: 3.3ms preprocess, 52.1ms inference, 57.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 54.8ms\n",
      "Speed: 3.3ms preprocess, 54.8ms inference, 56.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 54.3ms\n",
      "Speed: 1.7ms preprocess, 54.3ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 54.8ms\n",
      "Speed: 2.5ms preprocess, 54.8ms inference, 21.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.6ms\n",
      "Speed: 1.6ms preprocess, 52.6ms inference, 55.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 52.9ms\n",
      "Speed: 2.4ms preprocess, 52.9ms inference, 60.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 54.7ms\n",
      "Speed: 2.1ms preprocess, 54.7ms inference, 21.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.2ms\n",
      "Speed: 1.7ms preprocess, 52.2ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 53.0ms\n",
      "Speed: 3.2ms preprocess, 53.0ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.8ms\n",
      "Speed: 2.6ms preprocess, 52.8ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 51.8ms\n",
      "Speed: 1.9ms preprocess, 51.8ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 59.2ms\n",
      "Speed: 2.0ms preprocess, 59.2ms inference, 22.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 52.3ms\n",
      "Speed: 1.9ms preprocess, 52.3ms inference, 22.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 52.4ms\n",
      "Speed: 1.8ms preprocess, 52.4ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 53.8ms\n",
      "Speed: 1.9ms preprocess, 53.8ms inference, 23.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU (MPS) if available, otherwise use CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Load the YOLO model with pre-trained weights\n",
    "model = YOLO(\"../yoloweights/yolov8l.pt\").to(device)\n",
    "\n",
    "# Define class names for the detected objects\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Read the mask image for region selection\n",
    "mask = cv.imread('../mask/people_mask.png')\n",
    "\n",
    "# Initialize the SORT tracker for object tracking\n",
    "tracker = Sort(max_age=20, min_hits=2, iou_threshold=0.3)\n",
    "\n",
    "# Capture video from the specified file\n",
    "cap = cv.VideoCapture('../videos/people.mp4')\n",
    "\n",
    "# Load an overlay graphic image\n",
    "imagegraphic = cv.imread('../images/graphics.png', cv.IMREAD_UNCHANGED)\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps)\n",
    "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "\n",
    "# Set up the output video writer\n",
    "output_video = cv.VideoWriter(\"people_detected_video.mp4\", cv.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "\n",
    "# Define the upper and lower limits for counting objects\n",
    "limitsUp = [103, 161, 296, 161]\n",
    "limitsDown = [527, 489, 735, 489]\n",
    "\n",
    "# Initialize lists to keep track of counted objects\n",
    "total_countUp = []\n",
    "total_countDown = []\n",
    "\n",
    "# Process the video frame by frame\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break  # Exit loop if no more frames are available\n",
    "\n",
    "    # Overlay graphic on the current image\n",
    "    img = cvzone.overlayPNG(img, imagegraphic, (730, 260))\n",
    "\n",
    "    # Apply the mask to select the region of interest\n",
    "    imageRegion = cv.bitwise_and(img, mask)\n",
    "\n",
    "    # Initialize detections array\n",
    "    detections = np.empty((0, 5))\n",
    "    \n",
    "    # Perform inference on the image region using the YOLO model\n",
    "    results = model(imageRegion, stream=True)\n",
    "\n",
    "    # Iterate through results and extract bounding box information\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x, y, w, h = box.xywh[0]  # Get bounding box coordinates\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            \n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Get corners of the bounding box\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            conf = round(float(box.conf), 2)  # Confidence score of the detection\n",
    "            cls = int(box.cls[0])  # Class index of the detected object\n",
    "            currentClass = classNames[cls]  # Get the class name\n",
    "            \n",
    "            # Check if the detected object is a person and the confidence is above the threshold\n",
    "            if currentClass == 'person' and conf > 0.3:\n",
    "                # Display the class name and confidence on the image\n",
    "                cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, int(x - w/2)), max(35, int(y - h/2))), scale=0.7, thickness=1, offset=3)\n",
    "                # Optionally draw a rectangle around the detected person (commented out)\n",
    "                # cvzone.cornerRect(img, (int(x - w / 2), int(y - h / 2), w, h), l=5)\n",
    "                \n",
    "                # Store the detection in the detections array\n",
    "                currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currentArray))\n",
    "\n",
    "    # Draw lines for counting limits\n",
    "    cv.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 0, 255), thickness=3)\n",
    "    cv.line(img, (limitsDown[0], limitsDown[1]), (limitsDown[2], limitsDown[3]), (0, 0, 255), thickness=3)\n",
    "\n",
    "    # Update the tracker with the new detections\n",
    "    resultsTracker = tracker.update(detections)\n",
    "    \n",
    "    # Iterate through the tracked results\n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, ID = result  # Get coordinates and ID\n",
    "        x1, y1, x2, y2, ID = int(x1), int(y1), int(x2), int(y2), int(ID)\n",
    "        w, h = x2 - x1, y2 - y1  # Calculate width and height\n",
    "        \n",
    "        # Draw a rectangle around the tracked object\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=2, colorR=(255, 0, 0))\n",
    "        # Optionally display the ID of the tracked object (commented out)\n",
    "        # cvzone.putTextRect(img, f'{ID}', (max(0, x1), max(35, y1)), scale=1, thickness=3, offset=10)\n",
    "        \n",
    "        # Calculate the center of the bounding box\n",
    "        cx, cy = x1 + w // 2, y1 + h // 2\n",
    "        cv.circle(img, (cx, cy), 5, (255, 0, 0), -1)  # Draw a circle at the center\n",
    "\n",
    "        # Check if the center of the object crosses the upper limit\n",
    "        if limitsUp[0] < cx < limitsUp[2] and limitsUp[1] - 15 < cy < limitsUp[1] + 15:\n",
    "            if total_countUp.count(ID) == 0:  # Only count if not counted before\n",
    "                total_countUp.append(ID)  # Add ID to the count list\n",
    "                cv.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 255, 0), thickness=3)\n",
    "\n",
    "        # Check if the center of the object crosses the lower limit\n",
    "        if limitsDown[0] < cx < limitsDown[2] and limitsDown[1] - 15 < cy < limitsDown[1] + 15:\n",
    "            if total_countDown.count(ID) == 0:  # Only count if not counted before\n",
    "                total_countDown.append(ID)  # Add ID to the count list\n",
    "                cv.line(img, (limitsDown[0], limitsDown[1]), (limitsDown[2], limitsDown[3]), (0, 255, 0), thickness=3)\n",
    "\n",
    "    # Display the total count of objects that crossed the upper and lower limits\n",
    "    cv.putText(img, str(len(total_countUp)), (929, 345), cv.FONT_HERSHEY_PLAIN, 5, (139, 195, 75), 7)\n",
    "    cv.putText(img, str(len(total_countDown)), (1191, 345), cv.FONT_HERSHEY_PLAIN, 5, (50, 50, 230), 7)\n",
    "\n",
    "    # Show the processed image in a window\n",
    "    cv.imshow(\"Image\", img)\n",
    "    \n",
    "    # Write the processed frame to the output video file\n",
    "    output_video.write(img)\n",
    "    \n",
    "    # Exit the loop if 'q' key is pressed\n",
    "    if cv.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up resources\n",
    "cv.destroyAllWindows()\n",
    "cap.release()  # Release the video capture object\n",
    "output_video.release()  # Release the video writer object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
